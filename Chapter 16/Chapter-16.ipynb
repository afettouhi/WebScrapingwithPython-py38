{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Counter\n",
      "2 Counter\n",
      "3 Counter\n",
      "3 Fizz\n",
      "4 Counter\n",
      "5 Buzz\n",
      "5 Counter\n",
      "6 Fizz\n",
      "6 Counter\n",
      "7 Counter\n",
      "8 Counter\n",
      "9 Fizz\n",
      "9 Counter\n",
      "10 Buzz\n",
      "10 Counter\n",
      "11 Counter\n",
      "12 Fizz\n",
      "12 Counter\n",
      "13 Counter\n",
      "14 Counter\n",
      "15 Buzz\n",
      "15 Fizz\n",
      "15 Counter\n",
      "16 Counter\n",
      "17 Counter\n",
      "18 Fizz\n",
      "18 Counter\n",
      "19 Counter\n",
      "20 Buzz\n",
      "20 Counter\n",
      "21 Fizz\n",
      "21 Counter\n",
      "22 Counter\n",
      "23 Counter\n",
      "24 Fizz\n",
      "24 Counter\n",
      "25 Buzz\n",
      "25 Counter\n",
      "26 Counter\n",
      "27 Fizz\n",
      "27 Counter\n",
      "28 Counter\n",
      "29 Counter\n",
      "30 Buzz\n",
      "30 Fizz\n",
      "30 Counter\n",
      "31 Counter\n",
      "32 Counter\n",
      "33 Fizz\n",
      "33 Counter\n",
      "34 Counter\n",
      "35 Buzz\n",
      "35 Counter\n",
      "36 Fizz\n",
      "37 Counter\n",
      "38 Counter\n",
      "39 Counter\n",
      "39 Fizz\n",
      "40 Counter\n",
      "40 Buzz\n",
      "41 Counter\n",
      "42 Counter\n",
      "42 Fizz\n",
      "43 Counter\n",
      "44 Counter\n",
      "45 Counter\n",
      "45 Buzz\n",
      "45 Fizz\n",
      "46 Counter\n",
      "47 Counter\n",
      "48 Counter\n",
      "48 Fizz\n",
      "49 Counter\n",
      "50 Counter\n",
      "50 Buzz\n",
      "51 Counter\n",
      "51 Fizz\n",
      "52 Counter\n",
      "53 Counter\n",
      "54 Counter\n",
      "54 Fizz\n",
      "55 Counter\n",
      "55 Buzz\n",
      "56 Counter\n",
      "57 Counter\n",
      "57 Fizz\n",
      "58 Counter\n",
      "59 Counter\n",
      "60 Counter\n",
      "60 Buzz\n",
      "60 Fizz\n",
      "61 Counter\n",
      "62 Counter\n",
      "63 Counter\n",
      "63 Fizz\n",
      "64 Counter\n",
      "65 Buzz\n",
      "65 Counter\n",
      "66 Counter\n",
      "66 Fizz\n",
      "67 Counter\n",
      "68 Counter\n",
      "69 Counter\n",
      "69 Fizz\n",
      "70 Buzz\n",
      "70 Counter\n",
      "71 Counter\n",
      "72 Counter\n",
      "72 Fizz\n",
      "73 Counter\n",
      "74 Counter\n",
      "75 Buzz\n",
      "75 Counter\n",
      "75 Fizz\n",
      "76 Counter\n",
      "77 Counter\n",
      "78 Counter\n",
      "78 Fizz\n",
      "79 Counter\n",
      "80 Buzz\n",
      "80 Counter\n",
      "81 Fizz\n",
      "81 Counter\n",
      "82 Counter\n",
      "83 Counter\n",
      "84 Fizz\n",
      "84 Counter\n",
      "85 Buzz\n",
      "86 Counter\n",
      "87 Counter\n",
      "87 Fizz\n",
      "88 Counter\n",
      "89 Counter\n",
      "90 Counter\n",
      "90 Buzz\n",
      "90 Fizz\n",
      "91 Counter\n",
      "92 Counter\n",
      "93 Counter\n",
      "93 Fizz\n",
      "94 Counter\n",
      "95 Counter\n",
      "95 Buzz\n",
      "96 Counter\n",
      "96 Fizz\n",
      "97 Counter\n",
      "98 Counter\n",
      "99 Counter\n",
      "99 Fizz\n",
      "100 Counter\n",
      "100 Buzz\n",
      "101 Counter\n",
      "102 Counter\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-ea10fe8cce34>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;32mwhile\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m     \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import _thread\n",
    "import time\n",
    "\n",
    "def print_time(threadName, delay, iterations):\n",
    "    start = int(time.time())\n",
    "    for i in range(0,iterations):\n",
    "        time.sleep(delay)\n",
    "        seconds_elapsed = str(int(time.time()) - start)\n",
    "        print (\"{} {}\".format(seconds_elapsed, threadName))\n",
    "\n",
    "try:\n",
    "    _thread.start_new_thread(print_time, ('Fizz', 3, 33))\n",
    "    _thread.start_new_thread(print_time, ('Buzz', 5, 20))\n",
    "    _thread.start_new_thread(print_time, ('Counter', 1, 100))\n",
    "except:\n",
    "    print ('Error: unable to start thread')\n",
    "\n",
    "while 1:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Kevin Bacon in thread Thread 1\n",
      "Getting links in Thread 1\n",
      "/wiki/Gary_Sinise\n",
      "Scraping Monty Python in thread Thread 2\n",
      "Getting links in Thread 2\n",
      "/wiki/I%27ve_Got_Two_Legs\n",
      "Scraping Gary Sinise in thread Thread 1\n",
      "Getting links in Thread 1\n",
      "/wiki/Leonardo_DiCaprio\n",
      "Scraping I've Got Two Legs in thread Thread 2\n",
      "Getting links in Thread 2\n",
      "/wiki/List_of_recurring_Monty_Python%27s_Flying_Circus_characters\n",
      "Scraping Leonardo DiCaprio in thread Thread 1\n",
      "Getting links in Thread 1\n",
      "/wiki/Variety_(magazine)\n",
      "Scraping List of recurring Monty Python's Flying Circus characters in thread Thread 2\n",
      "Getting links in Thread 2\n",
      "/wiki/Piranha_Brothers\n",
      "Scraping Variety (magazine) in thread Thread 1\n",
      "Getting links in Thread 1\n",
      "/wiki/Archive.org\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-a1f14d048b6e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[0;32mwhile\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 36\u001B[0;31m     \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import random\n",
    "\n",
    "import _thread\n",
    "import time\n",
    "\n",
    "def get_links(thread_name, bs):\n",
    "    print('Getting links in {}'.format(thread_name))\n",
    "    return bs.find('div', {'id':'bodyContent'}).find_all('a',\n",
    "       href=re.compile('^(/wiki/)((?!:).)*$'))\n",
    "\n",
    "# Define a function for the thread\n",
    "def scrape_article(thread_name, path):\n",
    "    html = urlopen('http://en.wikipedia.org{}'.format(path))\n",
    "    time.sleep(5)\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "    title = bs.find('h1').get_text()\n",
    "    print('Scraping {} in thread {}'.format(title, thread_name))\n",
    "    links = get_links(thread_name, bs)\n",
    "    if len(links) > 0:\n",
    "        newArticle = links[random.randint(0, len(links)-1)].attrs['href']\n",
    "        print(newArticle)\n",
    "        scrape_article(thread_name, newArticle)\n",
    "\n",
    "\n",
    "# Create two threads as follows\n",
    "try:\n",
    "   _thread.start_new_thread(scrape_article, ('Thread 1', '/wiki/Kevin_Bacon',))\n",
    "   _thread.start_new_thread(scrape_article, ('Thread 2', '/wiki/Monty_Python',))\n",
    "except:\n",
    "   print ('Error: unable to start threads')\n",
    "\n",
    "while 1:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "visited = []\n",
    "def get_links(thread_name, bs):\n",
    "    print('Getting links in {}'.format(thread_name))\n",
    "    links = bs.find('div', {'id':'bodyContent'}).find_all('a',\n",
    "       href=re.compile('^(/wiki/)((?!:).)*$'))\n",
    "    return [link for link in links if link not in visited]\n",
    "\n",
    "def scrape_article(thread_name, path):\n",
    "    visited.append(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'myList' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-213cdc0c0438>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmyList\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'myList' is not defined"
     ]
    }
   ],
   "source": [
    "myList.pop(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'myList' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-d592372eb415>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmyList\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmyList\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'myList' is not defined"
     ]
    }
   ],
   "source": [
    "myList[len(myList)-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-94230e6cb2cd>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmy_list\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmy_list\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mmy_list\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmy_list\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'my_list' is not defined"
     ]
    }
   ],
   "source": [
    "my_list[i] = my_list[i] + 1\n",
    "my_list.append(my_list[-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'global_message' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-5963ac1e4a58>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Read the message in from the global list\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mmy_message\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mglobal_message\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;31m# Write a message back\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mglobal_message\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"I've retrieved the message\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;31m# do something with my_message\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'global_message' is not defined"
     ]
    }
   ],
   "source": [
    "# Read the message in from the global list\n",
    "my_message = global_message\n",
    "# Write a message back\n",
    "global_message = \"I've retrieved the message\"\n",
    "# do something with my_message"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in thread started by: <function storage at 0x7f8d151dcf70>\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-9-c9a8936bf470>\", line 11, in storage\n",
      "  File \"/home/af/Dokumenter/Programs/miniconda3/envs/WebScrapingwithPython-py38/lib/python3.8/site-packages/pymysql/__init__.py\", line 94, in Connect\n",
      "    return Connection(*args, **kwargs)\n",
      "  File \"/home/af/Dokumenter/Programs/miniconda3/envs/WebScrapingwithPython-py38/lib/python3.8/site-packages/pymysql/connections.py\", line 327, in __init__\n",
      "    self.connect()\n",
      "  File \"/home/af/Dokumenter/Programs/miniconda3/envs/WebScrapingwithPython-py38/lib/python3.8/site-packages/pymysql/connections.py\", line 619, in connect\n",
      "    raise exc\n",
      "pymysql.err.OperationalError: (2003, \"Can't connect to MySQL server on '127.0.0.1' ([Errno 2] No such file or directory)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Kevin Bacon for storage in thread Thread 1\n",
      "Getting links in Thread 1\n",
      "Added Monty Python for storage in thread Thread 2\n",
      "Getting links in Thread 2\n",
      "Added People (magazine) for storage in thread Thread 2\n",
      "Getting links in Thread 2\n",
      "Added Meryl Streep for storage in thread Thread 1\n",
      "Getting links in Thread 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-c9a8936bf470>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     58\u001B[0m \u001B[0;32mwhile\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 59\u001B[0;31m     \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import random\n",
    "import _thread\n",
    "from queue import Queue\n",
    "import time\n",
    "import pymysql\n",
    "\n",
    "def storage(queue):\n",
    "    conn = pymysql.connect(host='127.0.0.1', unix_socket='/tmp/mysql.sock',\n",
    "       user='root', passwd='', db='mysql', charset='utf8')\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('USE wiki_threads')\n",
    "    while 1:\n",
    "        if not queue.empty():\n",
    "            article = queue.get()\n",
    "            cur.execute('SELECT * FROM pages WHERE path = %s',\n",
    "               (article[\"path\"]))\n",
    "            if cur.rowcount == 0:\n",
    "                print(\"Storing article {}\".format(article[\"title\"]))\n",
    "                cur.execute('INSERT INTO pages (title, path) VALUES (%s, %s)', \\\n",
    "                    (article[\"title\"], article[\"path\"]))\n",
    "                conn.commit()\n",
    "            else:\n",
    "                print(\"Article already exists: {}\".format(article['title']))\n",
    "\n",
    "visited = []\n",
    "def getLinks(thread_name, bs):\n",
    "    print('Getting links in {}'.format(thread_name))\n",
    "    links = bs.find('div', {'id':'bodyContent'}).find_all('a',\n",
    "       href=re.compile('^(/wiki/)((?!:).)*$'))\n",
    "    return [link for link in links if link not in visited]\n",
    "\n",
    "def scrape_article(thread_name, path, queue):\n",
    "    visited.append(path)\n",
    "    html = urlopen('http://en.wikipedia.org{}'.format(path))\n",
    "    time.sleep(5)\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "    title = bs.find('h1').get_text()\n",
    "    print('Added {} for storage in thread {}'.format(title, thread_name))\n",
    "    queue.put({\"title\":title, \"path\":path})\n",
    "    links = getLinks(thread_name, bs)\n",
    "    if len(links) > 0:\n",
    "        newArticle = links[random.randint(0, len(links)-1)].attrs['href']\n",
    "        scrape_article(thread_name, newArticle, queue)\n",
    "\n",
    "queue = Queue()\n",
    "try:\n",
    "    _thread.start_new_thread(scrape_article, ('Thread 1',\n",
    "       '/wiki/Kevin_Bacon', queue,))\n",
    "    _thread.start_new_thread(scrape_article, ('Thread 2',\n",
    "       '/wiki/Monty_Python', queue,))\n",
    "    _thread.start_new_thread(storage, (queue,))\n",
    "except:\n",
    "    print ('Error: unable to start threads')\n",
    "\n",
    "while 1:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def print_time(threadName, delay, iterations):\n",
    "    start = int(time.time())\n",
    "    for i in range(0,iterations):\n",
    "        time.sleep(delay)\n",
    "        seconds_elapsed = str(int(time.time()) - start)\n",
    "        print ('{} {}'.format(seconds_elapsed, threadName))\n",
    "\n",
    "threading.Thread(target=print_time, args=('Fizz', 3, 33)).start()\n",
    "threading.Thread(target=print_time, args=('Buzz', 5, 20)).start()\n",
    "threading.Thread(target=print_time, args=('Counter', 1, 100)).start()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/af/Dokumenter/Programs/miniconda3/envs/WebScrapingwithPython-py38/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/af/Dokumenter/Programs/miniconda3/envs/WebScrapingwithPython-py38/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "TypeError: crawler() takes 1 positional argument but 20 were given\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "def crawler(url):\n",
    "    data = threading.local()\n",
    "    data.visited = []\n",
    "    # Crawl site\n",
    "\n",
    "threading.Thread(target=crawler, args=('http://brookings.edu')).start()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-12-2280b91490e7>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mthreading\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mThread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtarget\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcrawler\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "threading.Thread(target=crawler)\n",
    "t.start()\n",
    "\n",
    "while True:\n",
    "    time.sleep(1)\n",
    "    if not t.isAlive():\n",
    "        t = threading.Thread(target=crawler)\n",
    "        t.start()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Yugoslavism for storage in thread Thread 2\n",
      "Getting links in Thread 2\n",
      "Added Labour Party (Norway) for storage in thread Thread 1\n",
      "Getting links in Thread 1\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-f7494401b5d4>:25: DeprecationWarning: isAlive() is deprecated, use is_alive() instead\n",
      "  if not t.isAlive():\n",
      "Exception in thread Thread-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/af/Dokumenter/Programs/miniconda3/envs/WebScrapingwithPython-py38/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"<ipython-input-13-f7494401b5d4>\", line 15, in run\n",
      "Exception: Something bad happened!\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "class Crawler(threading.Thread):\n",
    "    def __init__(self):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.done = False\n",
    "\n",
    "    def isDone(self):\n",
    "        return self.done\n",
    "\n",
    "    def run(self):\n",
    "        time.sleep(5)\n",
    "        self.done = True\n",
    "        raise Exception('Something bad happened!')\n",
    "\n",
    "t = Crawler()\n",
    "t.start()\n",
    "\n",
    "while True:\n",
    "    time.sleep(1)\n",
    "    if t.isDone():\n",
    "        print('Done')\n",
    "        break\n",
    "    if not t.isAlive():\n",
    "        t = Crawler()\n",
    "        t.start()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Nuit Blanche for storage in thread Thread 1\n",
      "Getting links in Thread 1\n",
      "Counter\n",
      "Added International Biological Program for storage in thread Thread 2\n",
      "Getting links in Thread 2\n",
      "Counter\n",
      "FizzCounter\n",
      "\n",
      "Counter\n",
      "BuzzCounter\n",
      "\n",
      "Added Scarlet Sails (tradition) for storage in thread Thread 1\n",
      "Getting links in Thread 1\n",
      "Fizz\n",
      "Counter\n",
      "Added Molecular biology for storage in thread Thread 2\n",
      "Getting links in Thread 2\n",
      "Counter\n",
      "Counter\n",
      "Fizz\n",
      "Counter\n",
      "Buzz\n",
      "Counter\n",
      "Counter\n",
      "Added Gorod 312 for storage in thread Thread 1\n",
      "Getting links in Thread 1\n",
      "Added Food chemistry for storage in thread Thread 2\n",
      "Getting links in Thread 2\n",
      "Fizz\n",
      "Counter\n",
      "Counter\n",
      "Counter\n",
      "Fizz\n",
      "Buzz\n",
      "Counter\n",
      "Counter\n",
      "Added Timati for storage in thread Thread 1\n",
      "Getting links in Thread 1\n",
      "Counter\n",
      "Added Caribbean Public Health Agency for storage in thread Thread 2\n",
      "Getting links in Thread 2\n",
      "Fizz\n",
      "Counter\n",
      "Counter\n",
      "Buzz\n",
      "Counter\n",
      "Fizz\n",
      "Counter\n",
      "Added Egor Kreed for storage in thread Thread 1\n",
      "Getting links in Thread 1\n",
      "Counter\n",
      "Added Social distancing for storage in thread Thread 2\n",
      "Getting links in Thread 2\n",
      "Counter\n",
      "Fizz\n",
      "Counter\n",
      "Buzz\n",
      "Counter\n",
      "Counter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-3:\n",
      "Process Process-2:\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/af/Dokumenter/Programs/miniconda3/envs/WebScrapingwithPython-py38/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/af/Dokumenter/Programs/miniconda3/envs/WebScrapingwithPython-py38/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/af/Dokumenter/Programs/miniconda3/envs/WebScrapingwithPython-py38/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/af/Dokumenter/Programs/miniconda3/envs/WebScrapingwithPython-py38/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/af/Dokumenter/Programs/miniconda3/envs/WebScrapingwithPython-py38/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-14-273406347ffd>\", line 7, in print_time\n",
      "    time.sleep(delay)\n",
      "  File \"/home/af/Dokumenter/Programs/miniconda3/envs/WebScrapingwithPython-py38/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-14-273406347ffd>\", line 7, in print_time\n",
      "    time.sleep(delay)\n",
      "  File \"<ipython-input-14-273406347ffd>\", line 7, in print_time\n",
      "    time.sleep(delay)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-14-273406347ffd>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[0mp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mp\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mprocesses\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m     \u001B[0mp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/WebScrapingwithPython-py38/lib/python3.8/multiprocessing/process.py\u001B[0m in \u001B[0;36mjoin\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    147\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_parent_pid\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetpid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'can only join a child process'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    148\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_popen\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'can only join a started process'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 149\u001B[0;31m         \u001B[0mres\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_popen\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    150\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mres\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    151\u001B[0m             \u001B[0m_children\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdiscard\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/WebScrapingwithPython-py38/lib/python3.8/multiprocessing/popen_fork.py\u001B[0m in \u001B[0;36mwait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m     45\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m             \u001B[0;31m# This shouldn't block if wait() returned successfully.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 47\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpoll\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mWNOHANG\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0.0\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     48\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreturncode\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/WebScrapingwithPython-py38/lib/python3.8/multiprocessing/popen_fork.py\u001B[0m in \u001B[0;36mpoll\u001B[0;34m(self, flag)\u001B[0m\n\u001B[1;32m     25\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreturncode\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 27\u001B[0;31m                 \u001B[0mpid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msts\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwaitpid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mflag\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     28\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mOSError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m                 \u001B[0;31m# Child process not yet created. See #1731717\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "import time\n",
    "\n",
    "def print_time(threadName, delay, iterations):\n",
    "    start = int(time.time())\n",
    "    for i in range(0,iterations):\n",
    "        time.sleep(delay)\n",
    "        seconds_elapsed = str(int(time.time()) - start)\n",
    "        print (threadName if threadName else seconds_elapsed)\n",
    "\n",
    "\n",
    "processes = []\n",
    "processes.append(Process(target=print_time, args=('Counter', 1, 100)))\n",
    "processes.append(Process(target=print_time, args=('Fizz', 3, 33)))\n",
    "processes.append(Process(target=print_time, args=('Buzz', 5, 20)))\n",
    "\n",
    "for p in processes:\n",
    "    p.start()\n",
    "for p in processes:\n",
    "    p.join()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "11848"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# prints the child PID\n",
    "os.getpid()\n",
    "# prints the parent PID\n",
    "os.getppid()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "for p in processes:\n",
    "    p.join()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "cannot start a process twice",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-17-acc718eac590>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mp\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mprocesses\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     \u001B[0mp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Program complete'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/WebScrapingwithPython-py38/lib/python3.8/multiprocessing/process.py\u001B[0m in \u001B[0;36mstart\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    113\u001B[0m         '''\n\u001B[1;32m    114\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_closed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 115\u001B[0;31m         \u001B[0;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_popen\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'cannot start a process twice'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    116\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_parent_pid\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetpid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    117\u001B[0m                \u001B[0;34m'can only start a process object created by current process'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAssertionError\u001B[0m: cannot start a process twice"
     ]
    }
   ],
   "source": [
    "for p in processes:\n",
    "    p.start()\n",
    "print('Program complete')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "cannot start a process twice",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-18-8becbbefa1d5>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mp\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mprocesses\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     \u001B[0mp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mp\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mprocesses\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/WebScrapingwithPython-py38/lib/python3.8/multiprocessing/process.py\u001B[0m in \u001B[0;36mstart\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    113\u001B[0m         '''\n\u001B[1;32m    114\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_closed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 115\u001B[0;31m         \u001B[0;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_popen\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'cannot start a process twice'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    116\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_parent_pid\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetpid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    117\u001B[0m                \u001B[0;34m'can only start a process object created by current process'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAssertionError\u001B[0m: cannot start a process twice"
     ]
    }
   ],
   "source": [
    "for p in processes:\n",
    "    p.start()\n",
    "\n",
    "for p in processes:\n",
    "    p.join()\n",
    "print('Program complete')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Kevin Bacon in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/Billy_Bob_Thornton\n",
      "Scraping Monty Python in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/The_Spanish_Inquisition_(Monty_Python)\n",
      "Scraping The Spanish Inquisition (Monty Python) in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/The_Seventh_Python\n",
      "Scraping Billy Bob Thornton in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/Kevin_Willmott\n",
      "Scraping The Seventh Python in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/Rutland_Weekend_Television\n",
      "Scraping Kevin Willmott in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/Philip_G._Epstein\n",
      "Scraping Rutland Weekend Television in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/Tonto\n",
      "Scraping Philip G. Epstein in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/Arsenic_and_Old_Lace_(film)\n",
      "Scraping Tonto in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/Native_Americans_in_the_United_States\n",
      "Scraping Arsenic and Old Lace (film) in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/Strychnine\n",
      "Scraping Strychnine in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/Novichok_agent\n",
      "Scraping Native Americans in the United States in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/Cherokee_syllabary\n",
      "Scraping Novichok agent in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/Neurotransmitter_release\n",
      "Scraping Cherokee syllabary in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/Flag_semaphore\n",
      "Scraping Exocytosis in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/Pinocytosis\n",
      "Scraping Flag semaphore in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/3_(number)\n",
      "Scraping Pinocytosis in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/Macropinosome\n",
      "Scraping 3 in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/30000_(number)\n",
      "Scraping Macropinosome in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/PMID_(identifier)\n",
      "Scraping 30,000 in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/MathWorld\n",
      "Scraping PubMed in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/Telehealth\n",
      "Scraping MathWorld in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/List_of_online_encyclopedias\n",
      "Scraping Telehealth in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/PMID_(identifier)\n",
      "Scraping List of online encyclopedias in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/Enciclopedia_Libre_Universal_en_Espa%C3%B1ol\n",
      "Scraping PubMed in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/Tele-audiology\n",
      "Scraping Enciclopedia Libre Universal en Español in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/El_Pa%C3%ADs\n",
      "Scraping Tele-audiology in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/Participative_decision-making_in_organizations\n",
      "Scraping El País in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/Europeanism\n",
      "Scraping Participative decision-making in organizations in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/Doi_(identifier)\n",
      "Scraping Europeanism in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/Citizenship\n",
      "Scraping Digital object identifier in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/ISO_1000\n",
      "Scraping Citizenship in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/Doi_(identifier)\n",
      "Scraping ISO 1000 in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/ISO_10487\n",
      "Scraping Digital object identifier in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/ISO_22300\n",
      "Scraping Connectors for car audio in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/Citro%C3%ABn_C3\n",
      "Scraping ISO 22300 in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/ISO_5964\n",
      "Scraping Citroën C3 in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/Car_classification\n",
      "Scraping ISO 5964 in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/ISO_3977\n",
      "Scraping Car classification in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/List_of_motorcycle_manufacturers\n",
      "Scraping ISO 3977 in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/ISO/IEC_8859-3\n",
      "Scraping List of motorcycle manufacturers in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/Rajdoot_350\n",
      "Scraping ISO/IEC 8859-3 in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/Ventura_Symbol\n",
      "Scraping Rajdoot 350 in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/TVS_Scooty\n",
      "Scraping Symbol (typeface) in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/Unicode_character_property#General_Category\n",
      "Scraping TVS Scooty in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/Hero_Karizma\n",
      "Scraping Unicode character property in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/Unicode_plane#Basic_Multilingual_Plane\n",
      "Scraping Hero Karizma in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/South_America\n",
      "Scraping Plane (Unicode) in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/Cyrillic_Extended-B\n",
      "Scraping South America in process 13524\n",
      "Getting links in 13524\n",
      "/wiki/Freedom_suit\n",
      "Scraping Cyrillic Extended-B in process 13525\n",
      "Getting links in 13525\n",
      "/wiki/%EA%99%AC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-4:\n",
      "Process Process-5:\n",
      "Traceback (most recent call last):\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import random\n",
    "\n",
    "from multiprocessing import Process\n",
    "import os\n",
    "import time\n",
    "\n",
    "visited = []\n",
    "def get_links(bs):\n",
    "    print('Getting links in {}'.format(os.getpid()))\n",
    "    links = bs.find('div', {'id':'bodyContent'}).find_all('a',\n",
    "       href=re.compile('^(/wiki/)((?!:).)*$'))\n",
    "    return [link for link in links if link not in visited]\n",
    "\n",
    "def scrape_article(path):\n",
    "    visited.append(path)\n",
    "    html = urlopen('http://en.wikipedia.org{}'.format(path))\n",
    "    time.sleep(5)\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "    title = bs.find('h1').get_text()\n",
    "    print('Scraping {} in process {}'.format(title, os.getpid()))\n",
    "    links = get_links(bs)\n",
    "    if len(links) > 0:\n",
    "        newArticle = links[random.randint(0, len(links)-1)].attrs['href']\n",
    "        print(newArticle)\n",
    "        scrape_article(newArticle)\n",
    "\n",
    "processes = []\n",
    "processes.append(Process(target=scrape_article, args=('/wiki/Kevin_Bacon',)))\n",
    "processes.append(Process(target=scrape_article, args=('/wiki/Monty_Python',)))\n",
    "\n",
    "for p in processes:\n",
    "    p.start()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def scrape_article(path):\n",
    "    visited.append(path)\n",
    "    print(\"Process {} list is now: {}\".format(os.getpid(), visited))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Kevin Bacon in process 14213\n",
      "Scraping Monty Python in process 14214\n",
      "Scraping Kevin Bacon (disambiguation) in process 14213\n",
      "Scraping Philadelphia in process 14214\n",
      "Scraping Kyra Sedgwick in process 14213\n",
      "Scraping Sosie Bacon in process 14214\n",
      "Scraping Edmund Bacon (architect) in process 14213\n",
      "Scraping Michael Bacon (musician) in process 14214\n",
      "Scraping Footloose (1984 film) in process 14214\n",
      "Scraping Holly Near in process 14213\n",
      "Scraping A Few Good Men in process 14213\n",
      "Scraping JFK (film) in process 14214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-8:\n",
      "Process Process-7:\n",
      "Traceback (most recent call last):\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import random\n",
    "from multiprocessing import Process, Queue\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "def task_delegator(taskQueue, urlsQueue):\n",
    "    #Initialize with a task for each process\n",
    "    visited = ['/wiki/Kevin_Bacon', '/wiki/Monty_Python']\n",
    "    taskQueue.put('/wiki/Kevin_Bacon')\n",
    "    taskQueue.put('/wiki/Monty_Python')\n",
    "\n",
    "    while 1:\n",
    "        # Check to see if there are new links in the urlsQueue\n",
    "       # for processing\n",
    "        if not urlsQueue.empty():\n",
    "            links = [link for link in urlsQueue.get() if link not in visited]\n",
    "            for link in links:\n",
    "                #Add new link to the taskQueue\n",
    "                taskQueue.put(link)\n",
    "\n",
    "def get_links(bs):\n",
    "    links = bs.find('div', {'id':'bodyContent'}).find_all('a',\n",
    "       href=re.compile('^(/wiki/)((?!:).)*$'))\n",
    "    return [link.attrs['href'] for link in links]\n",
    "\n",
    "def scrape_article(taskQueue, urlsQueue):\n",
    "    while 1:\n",
    "        while taskQueue.empty():\n",
    "            #Sleep 100 ms while waiting for the task queue\n",
    "            #This should be rare\n",
    "            time.sleep(.1)\n",
    "        path = taskQueue.get()\n",
    "        html = urlopen('http://en.wikipedia.org{}'.format(path))\n",
    "        time.sleep(5)\n",
    "        bs = BeautifulSoup(html, 'html.parser')\n",
    "        title = bs.find('h1').get_text()\n",
    "        print('Scraping {} in process {}'.format(title, os.getpid()))\n",
    "        links = get_links(bs)\n",
    "        #Send these to the delegator for processing\n",
    "        urlsQueue.put(links)\n",
    "\n",
    "\n",
    "processes = []\n",
    "taskQueue = Queue()\n",
    "urlsQueue = Queue()\n",
    "processes.append(Process(target=task_delegator, args=(taskQueue, urlsQueue,)))\n",
    "processes.append(Process(target=scrape_article, args=(taskQueue, urlsQueue,)))\n",
    "processes.append(Process(target=scrape_article, args=(taskQueue, urlsQueue,)))\n",
    "\n",
    "for p in processes:\n",
    "    p.start()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}